----
title: "Stressors: targeted fishing by species and cell - calculate total fishing catch"
author: "*Compiled on `r date()` by `r Sys.info()['user']`*"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_depth: 1
    toc_float: yes
    number_sections: false
    theme: cerulean
    highlight: haddock
    includes: 
      in_header: '~/github/src/templates/ohara_hdr.html'
  pdf_document:
    toc: true
---

``` {r setup, echo = TRUE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

library(oharac) ### remotes::install_github('oharac/oharac')
  ### includes some helper functions, e.g., dt_join
library(tidyverse)
library(here)
library(sf)
library(terra)

source(here('common_fxns.R'))
source('stressor_fxns.R') ### in same dir as this Rmd
```

# Summary

Read in data from Watson (2018) and collapse down to targeted catch by taxon and cell, across benthic gear types and pelagic gear types separately.  Save out as rasters (or csvs) per species.

# Data

Data from

* Watson, R.A. and Tidd, A.N. (2018) Mapping nearly a century and a half of global marine fishing: 1869 to 2015. Marine Policy 93, 171-177
* Watson, R. (2017) A database of global marine commercial, small-scale, illegal and unreported fisheries catch 1950-2014. Nature Scientific Data 4 (170039).

Included in data:

* Industrial Catch (1950 - 2017) - reported, iuu, and discard catch data for each cell location and unique identifier
* Non-Industrial Catch (1950 - 2017) - reported, iuu, and discard catch data for each cell location and unique identifier
* DATA CODE DEFINITIONS (gear/taxa/country codes and cell lat/lon references)

# Methods

## Read in Watson catch data

```{r read in watson catch data}
w_dir <- file.path('/home/shares/ohi/git-annex/globalprep/_raw_data', 
                   'IMAS_GlobalFisheriesLandings/d2020')

w_codes_xlsx <- file.path(w_dir, 'Codes_raw.xlsx')
# codes_sheets <- readxl::excel_sheets(codes_xlsx)

w_cell_df_raw <- readxl::read_excel(w_codes_xlsx, sheet = 'Cell') %>%
  janitor::clean_names() %>%
  select(cell_id = cell, x = lon_centre, y = lat_centre, ocean_a_km2 = ocean_areasqkm)

### use bc boundary function to automate min latitude
lat_min <- create_bc_sf() %>%
  st_bbox() %>% .['ymin']
w_cell_df <- w_cell_df_raw %>%
  filter(y >= lat_min)

w_gear_df <- readxl::read_excel(w_codes_xlsx, sheet = 'Gear') %>%
  janitor::clean_names() %>%
  select(-x9, -x10)
### Benthic gears: trap (f_gear_code = 4), dredge (5), trawl (6)

w_taxa_raw_df <- readxl::read_excel(w_codes_xlsx, sheet = 'Taxa') %>% 
  janitor::clean_names() %>%
  select(-c(x8:taxonkey_11), taxonkey = taxonkey_1)

w_catch_df <- readRDS(file.path(w_dir, 'Catch2015_2019.rds')) %>%
  janitor::clean_names() %>%
  mutate(benthic = f_gear_code %in% 4:6)

tons_by_pel_benth <- w_catch_df %>%
  filter(i_year == 2016) %>%
  group_by(benthic) %>%
  summarize(tot_tonnes = sum(reported_ind + reported_nind + iuuind + iuunind))

```

### Check catch levels across various taxonomic levels

Check 2016 catch to get an idea of how much catch is aggregated into higher-order taxa.

```{r summarize catch data across taxa for inspection}
summary_catch_by_tx <- w_catch_df %>%
  filter(i_year == 2016) %>%
  group_by(taxonkey) %>%
  summarize(tot_ind = sum(reported_ind + iuuind),
            tot_nind = sum(reported_nind + iuunind),
            tot_catch = tot_ind + tot_nind) %>%
  mutate(level = floor(taxonkey / 1e5))

tx_missing <- w_taxa_raw_df %>%
  filter(!taxonkey %in% summary_catch_by_tx$taxonkey)

ggplot(summary_catch_by_tx, aes(x = level, y = tot_catch)) +
  geom_jitter(width = .2, height = 0)

```

The large outlier is taxon 100039 (Marine fishes not identified, demersal <30 cm, Misc Finfishes) 

``` {r}
misc_finfish <- w_catch_df %>%
  filter(taxonkey == 100039) %>%
  filter(i_year == 2016) %>%
  summarize(tot_ind_catch = sum(reported_ind + iuuind),
            tot_nind_catch = sum(reported_nind + iuunind),
            tot_catch = tot_ind_catch + tot_nind_catch)
tot_2016 <- w_catch_df %>%
  filter(i_year == 2016) %>%
  summarize(tot_ind_catch = sum(reported_ind + iuuind),
            tot_nind_catch = sum(reported_nind + iuunind),
            tot_catch = tot_ind_catch + tot_nind_catch)

```

__NOTE:__  taxon 100039 (Marine fishes not identified, demersal <30 cm, Misc Finfishes) is a huge catch, nearly 1/10th total catch (reported and iuu).  Most is industrial.  This could skew results when assigning aggregated higher-level catch to species, unless we filter out the big fish (> 30 cm).  We can get length estimates from our functional entities post-imputation dataset.  Assume non-listed species are smaller than 30 cm; large spp are easier to identify.  

## Grab data from global analysis

```{r taxa to species lookup}
### created in spp_vuln_mapping project
watson_maps_lookup <- read_csv(here('1_setup/stressors/int/watson_maps_lookup.csv')) %>%
  mutate(level = floor(taxonkey / 1e5)) %>%
  left_join(w_taxa_raw_df %>% select(taxonkey, taxon_name))
```


### Process catch totals for higher level taxa

Functions to map the taxon species richness and total catch per cell for the taxon:

* `map_tx_spp_richness(spp_in_taxon, am_spp_cells, iucn_spp_cells)`
* `map_tx_catch(tx_id, catch_df)`

```{r helper functions}

map_tx_spp_rich <- function(spp_in_taxon, am_spp_cells, iucn_spp_cells) {
  
  am_sids <- spp_in_taxon %>%
    filter(source == 'aquamaps') %>%
    .$am_sid
  iucn_sids <- spp_in_taxon %>%
    filter(source == 'iucn') %>%
    .$iucn_sid
  
  ### find cells for all AquaMaps spp in this taxon
  am_tx_cells <- am_spp_cells %>%
    filter(am_sid %in% am_sids) %>%
    rename(id = am_sid)
  ### find cells for all IUCN spp in this taxon
  iucn_tx_cells <- iucn_spp_cells %>%
    filter(iucn_sid %in% iucn_sids) %>%
    mutate(id = as.character(iucn_sid)) ### to join with character am_sid

  
  tx_cell_sum <- am_tx_cells %>%
    bind_rows(iucn_tx_cells) %>%
    group_by(loiczid) %>%
    summarize(n_spp = n_distinct(id))
  
  if(nrow(tx_cell_sum) == 0) {
    message('  ... no species range found for ', paste(am_sids, iucn_sids, sep = ';', collapse = ';'), '!')
  }
  
  return(tx_cell_sum)
}

map_tx_catch <- function(tx_id, catch_df) {
  tx_catch_sum <- catch_df %>%
    filter(taxonkey %in% tx_id) %>%
    mutate(pel_ind_catch  = (reported_ind  + iuuind) * (!benthic),
           pel_nind_catch = (reported_nind + iuunind) * (!benthic),
           ben_ind_catch  = (reported_ind  + iuuind) * (benthic),
           ben_nind_catch = (reported_nind + iuunind) * (benthic)) %>%
    group_by(cell) %>%
    summarize(pel_ind_catch  = sum(pel_ind_catch),
              pel_nind_catch = sum(pel_nind_catch),
              ben_ind_catch  = sum(ben_ind_catch),
              ben_nind_catch = sum(ben_nind_catch),
              pel_tot_catch  = pel_ind_catch + pel_nind_catch,
              ben_tot_catch  = ben_ind_catch + ben_nind_catch)
  
  ### at this point, not using industrial vs non-industrial, so drop distinction.
  ### If it is needed, add to select() here:
  tx_catch_sum <- tx_catch_sum %>%
    select(cell, pel_tot_catch, ben_tot_catch)
  
  if(nrow(tx_catch_sum) == 0) {
    message('  ... no observed catch for taxon ', tx_id, '!')
  }
  return(tx_catch_sum)
}
```

Loop over higher-order taxa and generate taxon catch summary files.  For 100039, filter out big species specifically for a more accurate species richness value.  Write out to `stressors/fishing/1_total_catch_by_tx_cell` in the Mazu annex directory.

```{r Read in species maps}
### this is the IUCN spp mapped to HCAF, generated in 1_setup/species/2_rasterize_iucn_spp_shps.Rmd:
iucn_spp_cells <- data.table::fread(here_anx('iucn_spp', 'iucn_spp_hcaf.csv'))



am_dir <- '/home/shares/ohi/spp_vuln/aquamaps_2021'

am_spp_bc <- read_csv(here('_data/am_spp_bc.csv'))
  ### created in 1_setup/species/1_map_aquamaps_to_bc.Rmd

### cut to occur_cells >= 10 in 1_setup/species/_identify_bc_spp_from_global.Rmd

am_spp_cell_f <- file.path(am_dir, 'hcaf_species_native_clean.csv')
am_spp_cells <- data.table::fread(am_spp_cell_f) %>%
  filter(am_sid %in% am_spp_bc$am_sid) %>%
  filter(loiczid <= max(iucn_spp_cells$loiczid, na.rm = TRUE))
```


```{r process higher order taxa}
process_higher_taxa <- function(i, tx_high) {
  ### i <- 1
  ### i <- which(tx_high$taxonkey == 590107)
  tx_id <- tx_high$taxonkey[i]
  tx_nm <- tx_high$taxon_name[i] %>%
    tolower() %>%
    str_replace_all('[^a-z]+', '_')
  
  tx_map_fstem <- here_anx('stressors/fishing', 
                           '1_total_catch_by_tx_cell/tx_catch_%s_%s.csv')
  # unlink(list.files(dirname(tx_map_fstem), full.names = TRUE))
  tx_map_f <- sprintf(tx_map_fstem, tx_id, tx_nm)
  
  if(!file.exists(tx_map_f)) {
    message('Processing ', basename(tx_map_f), '...')
    spp_in_taxon <- tx_high %>%
      filter(taxonkey == tx_id) %>%
      select(am_sid, iucn_sid, source) %>%
      distinct()
    
    tx_spp_rich <- map_tx_spp_rich(spp_in_taxon, am_spp_cells = am_spp_cells, 
                                   iucn_spp_cells = iucn_spp_cells)
  
    tx_catch <- map_tx_catch(tx_id = tx_id, catch_df = w_catch_df)
    tx_catch_total <- tx_catch %>%
      summarize(tot_catch = sum(pel_tot_catch + ben_tot_catch)) %>%
      .$tot_catch %>% round(2)
    
    tx_map_out <- inner_join(tx_spp_rich, tx_catch, by = c('loiczid' = 'cell'))
    
    if(nrow(tx_map_out) == 0) {
      if(nrow(tx_spp_rich > 0) & nrow(tx_catch > 0)) {
        message('  ... no observed overlap of catch and species range for ', tx_id, ': ', tx_nm,
                '\n      this drops ', tx_catch_total, ' tonnes of catch...')
      }
      tx_map_out <- data.frame(loiczid = -1, n_spp = NA,
                               pel_tot_catch = 0, ben_tot_catch = 0)
    }
    
    write_csv(tx_map_out, tx_map_f)
  } else {
    # message('File ', basename(tx_map_f), ' already exists... skipping!')
  }
}
```

```{r}
tx_high <- watson_maps_lookup %>%
  filter(level < 6)

tmp <- parallel::mclapply(1:nrow(tx_high), mc.cores = 12,
                          FUN = process_higher_taxa, 
                          tx_high = tx_high)
```


## Species-level catch maps

Here, for each species in AquaMaps and IUCN, total up the catch associated with that species at the species level and at higher taxonomic levels, per LOICZID cell.  Write out as .csv.

Note, due to name mismatches and synonyms between AquaMaps, IUCN, and WoRMS, some species are listed across multiple species IDs.

Helper functions:

* `build_spp_catch_map()`: generate catch map across potentially multiple `taxonkey` values.
    * First collect higher-taxon-level catch per cell, dividing that by the number of similar species per cell, and assigning that value to the species
    * Then collect the species-specific catch
    * All catch values are summed and assigned to each cell
    * Result is saved out to Mazu for each species.  
        * Note, saved just by species name, not ID because multiple `am_sid` values map to a single species (e.g., for subspecies or synonyms)

```{r moar helper functions}

build_spp_catch_map <- function(tx_ids, tx_nms) {
  hi_taxa_ids <- tx_ids[tx_ids < 600000]
  hi_taxa_nms <- tx_nms[tx_ids < 600000]
  
  if(length(hi_taxa_ids) > 0) {
    fs <- here_anx('stressors/fishing/1_total_catch_by_tx_cell/tx_catch_%s_%s.csv') %>%
      sprintf(hi_taxa_ids, str_replace_all(tolower(hi_taxa_nms), '[^a-z]+', '_'))
    
    taxa_catch <- lapply(fs, read_csv, show_col_types = FALSE) %>%
      setNames(hi_taxa_ids) %>%
      bind_rows(.id = 'taxonkey') %>%
      mutate(pel_assigned_catch = pel_tot_catch / n_spp,
             ben_assigned_catch = ben_tot_catch / n_spp) %>%
      group_by(loiczid) %>%
      summarize(pel_tot_catch = sum(pel_assigned_catch),
                ben_tot_catch = sum(ben_assigned_catch))
  } else {
    taxa_catch = data.frame() ### empty dataframe as placeholder
  }
  
  spp_ids <- tx_ids[tx_ids >= 600000]
  if(length(spp_ids) == 0) {
    message('  No species-level taxonkey found... returning catch from higher taxa')
    return(taxa_catch)
  } 
  
  spp_catch <- map_tx_catch(tx_id = spp_ids, catch_df = w_catch_df) %>%
    rename(loiczid = cell)
  
  tot_catch_df <- bind_rows(taxa_catch, spp_catch) %>%
    group_by(loiczid) %>%
    summarize(pel_tot_catch = sum(pel_tot_catch),
              ben_tot_catch = sum(ben_tot_catch))
  
  return(tot_catch_df)
}
```


```{r process species level catch}

process_species_catch <- function(s, spp_vec, spp_map_fstem, source = 'aquamaps') {
  # s <- 'gadus macrocephalus' ### multiple taxonkey at spp level
  # s <- 'platybelone argalus' ### multiple am_sid
  # s <- 'lepas anatifera' ### file not being created
  # s <- am_spp_vec[1] s <- spp_vec[1]
  i <- which(s == spp_vec)
  
  spp_map_f <- sprintf(spp_map_fstem, str_replace_all(s, ' +', '_'))
  
  if(!file.exists(spp_map_f)) {
    
    message('Processing species-total catch map for ', s, 
            ' (', i, ' of ', length(spp_vec), ')')
  
    s_df <- watson_maps_lookup %>%
      filter(spp == s)
    
    spp_ids <- s_df %>%
      select(am_sid, iucn_sid, source) %>%
      distinct()
    
    spp_map <- map_tx_spp_rich(spp_ids, 
                               am_spp_cells = am_spp_cells, 
                               iucn_spp_cells = iucn_spp_cells) %>%
      select(-n_spp)
    
    tx_keys_df <- s_df %>%
      select(taxonkey, taxon_name) %>%
      distinct()
    tx_ids <- tx_keys_df$taxonkey %>% unique()
    tx_nms <- tx_keys_df$taxon_name
    catch_map <- build_spp_catch_map(tx_ids, tx_nms)
    
    spp_catch_map <- spp_map %>%
      inner_join(catch_map, by = 'loiczid')
    
    tot_catch <- spp_catch_map %>%
      summarize(tot_catch = sum(pel_tot_catch + ben_tot_catch)) %>%
      .$tot_catch %>% round(2)
    
    # raster::plot(map_to_hcaf(spp_catch_map, which = 'pel_tot_catch'))
    
    message('  Found ', nrow(spp_catch_map), ' catch/presence cells for ', s, 
            ' totalling ', tot_catch, ' tonnes...')
    if(nrow(spp_catch_map) == 0) {
      spp_catch_map <- data.frame(loiczid = -1, pel_tot_catch = 0, ben_tot_catch = 0)
    }
    
    write_csv(spp_catch_map, spp_map_f)
    
  } else {
    # message('File ', basename(spp_map_f), ' exists... skipping!')
  }
}
```

``` {r iterate over AquaMaps species IDs}

am_spp_vec <- watson_maps_lookup %>%
  filter(source == 'aquamaps') %>%
  filter(am_sid %in% am_spp_bc$am_sid) %>%
  .$spp %>% 
  unique() %>% sort()
    ### 17392 spp

am_spp_map_fstem <- here_anx('stressors/fishing/2_total_catch_by_spp_cell',
                          'am_spp_catch_%s.csv')

x <- list.files(dirname(am_spp_map_fstem), pattern = 'am_spp_catch', full.names = TRUE)
### unlink(x)

# x <- list.files(dirname(am_spp_map_fstem), full.names = TRUE)
# drop <- data.frame(f = x, y = file.size(x)) %>% filter(y < 100) %>% .$f
### unlink(drop)

### don't rerun species already done...
spp_with_files <- basename(x) %>% 
  str_remove_all('am_spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

am_spp_vec <- am_spp_vec[!am_spp_vec %in% spp_with_files]

if(length(am_spp_vec) > 0) {
  tmp <- parallel::mclapply(am_spp_vec, mc.cores = 12,
                            FUN = process_species_catch, 
                            spp_vec = am_spp_vec,
                            spp_map_fstem = am_spp_map_fstem)
}
```

``` {r iterate over IUCN species}
### While we prioritized AquaMaps over IUCN, here let's just run all the 
### available IUCN species in case we change our priority later...
bc_spp_info <- get_spp_info()

iucn_spp_vec <- watson_maps_lookup %>%
  filter(!is.na(iucn_sid)) %>%
  filter(iucn_sid %in% bc_spp_info$iucn_sid) %>%
  .$spp %>% 
  unique() %>% sort()
    ### 4744 spp

iucn_spp_map_fstem <- here_anx('stressors/fishing/2_total_catch_by_spp_cell',
                          'iucn_spp_catch_%s.csv')

x <- list.files(dirname(iucn_spp_map_fstem), pattern = 'iucn_spp_catch',
                full.names = TRUE)
### unlink(x)

spp_with_files <- basename(x) %>% 
  str_remove_all('iucn_spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

iucn_spp_vec <- iucn_spp_vec[!iucn_spp_vec %in% spp_with_files]

if(length(iucn_spp_vec) > 0) {
  tmp <- parallel::mclapply(iucn_spp_vec, mc.cores = 12,
                            FUN = process_species_catch, 
                            spp_vec = iucn_spp_vec,
                            spp_map_fstem = iucn_spp_map_fstem,
                            source = 'iucn')
}

```

```{r check results, eval = FALSE, include = FALSE}
x <- list.files(dirname(iucn_spp_map_fstem), full.names = TRUE)

### unlink zero-length files if necessary to reprocess
# df <- data.frame(x, fsize = file.size(x))
# y <- df %>% filter(fsize < 100) %>% .$x
# unlink(y)

spp_with_files <- basename(x) %>% 
  str_remove_all('^am_|^iucn_|spp_catch_|.csv') %>% 
  str_replace_all('_', ' ')

spp_wo_files <- spp_vec[!spp_vec %in% spp_with_files]
head(spp_wo_files)
```

